{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile as wav\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from collections import defaultdict\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from python_speech_features import *\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = ['p1', 'p2', 'p3', 'p4', 'p5']\n",
    "directory_list = ['number', 'sentence', 'word']\n",
    "data_path = 'data/final_data/'\n",
    "\n",
    "trainset = {}\n",
    "trainset['number'] = random.sample(range(10), 5)\n",
    "trainset['sentence'] = random.sample(range(30), 15)\n",
    "trainset['word'] = random.sample(range(20), 10)\n",
    "\n",
    "testset = {}\n",
    "testset['number'] = [x for x in range(10) if not x in trainset['number']]\n",
    "testset['sentence'] = [x for x in range(30) if not x in trainset['sentence']]\n",
    "testset['word'] = [x for x in range(20) if not x in trainset['word']]\n",
    "\n",
    "def calculate_nfft(samplerate, winlen):\n",
    "    window_length_samples = winlen * samplerate\n",
    "    nfft = 1\n",
    "    while nfft < window_length_samples:\n",
    "        nfft *= 2\n",
    "    return nfft\n",
    "\n",
    "def preprocess(energy, feat):\n",
    "    bound = 1.5 * sum(energy[:100]) / 100\n",
    "    ret = []\n",
    "    for i in range(len(energy)):\n",
    "        if energy[i] >= bound:\n",
    "            ret.append(np.log(feat[i, :]))\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_feature = defaultdict(list)\n",
    "for person in person_list:\n",
    "    for directory in directory_list:\n",
    "        filelist = os.listdir('{}{}/{}/'.format(data_path, person, directory))\n",
    "        for i in trainset[directory]:\n",
    "            signal = np.load('{}{}/{}/{}'.format(data_path, person, directory, filelist[i]))\n",
    "            fs = 44100\n",
    "            feat, energy = fbank(signal, samplerate = fs, nfft=calculate_nfft(fs, 0.025))\n",
    "            ffeat = preprocess(energy, feat)\n",
    "            person_feature[person].extend(ffeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.403000116348267\n"
     ]
    }
   ],
   "source": [
    "person_gmms = []\n",
    "start_time = time.time()\n",
    "\n",
    "for name, feats in person_feature.items():\n",
    "    gmm = GaussianMixture(n_components=20, max_iter = 10000)\n",
    "    gmm.fit(feats, name)\n",
    "    person_gmms.append(gmm)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 0 Ashley_1528934.mp3.npy\n",
      "p1 0 Ashley_2951876.mp3.npy\n",
      "p1 0 Ashley_5960178.mp3.npy\n",
      "p1 0 Ashley_7429316.mp3.npy\n",
      "p1 0 Ashley_9675431.mp3.npy\n",
      "p1 0 Ashley_All_I_need_is_some_rest.mp3.npy\n",
      "p1 0 Ashley_Are_you_done_with_the_report.mp3.npy\n",
      "p1 0 Ashley_Can_you_give_me_a_chance.mp3.npy\n",
      "p1 0 Ashley_Even_miracles_take_a_little_time.mp3.npy\n",
      "p1 0 Ashley_I_am_just_about_to_go_to_bed.mp3.npy\n",
      "p1 0 Ashley_I_ate_his_liver_with_some_fava_beans_and_a_nice_Chianti.mp3.npy\n",
      "p1 0 Ashley_I_don’t_think_we_are_in_Kansas_anymore.mp3.npy\n",
      "p1 0 Ashley_I_want_to_access.mp3.npy\n",
      "p1 0 Ashley_That_is_why_I´m_so_tired.mp3.npy\n",
      "p1 0 Ashley_What_do_you_usually_do_in_your_free_time.mp3.npy\n",
      "p1 0 Ashley_What_do_you_want_to_do_today.mp3.npy\n",
      "p1 0 Ashley_Which_one_do_you_want.mp3.npy\n",
      "p1 0 Ashley_Why_are_you_always_putting_me_down.mp3.npy\n",
      "p1 0 Ashley_Would_you_please_be_quiet.mp3.npy\n",
      "p1 0 Ashley_You're_never_wrong_to_do_the_right_things.mp3.npy\n",
      "p1 0 Ashley_education.mp3.npy\n",
      "p1 0 Ashley_explanation.mp3.npy\n",
      "p1 0 Ashley_homogeneous.mp3.npy\n",
      "p1 0 Ashley_innocuous.mp3.npy\n",
      "p1 0 Ashley_meticulous.mp3.npy\n",
      "p1 0 Ashley_piezoelectricity.mp3.npy\n",
      "p1 0 Ashley_precarious.mp3.npy\n",
      "p1 0 Ashley_precipitately.mp3.npy\n",
      "p1 0 Ashley_revolution.mp3.npy\n",
      "p1 0 Ashley_substantive.mp3.npy\n",
      "p2 1 Hugh_1528934.mp3.npy\n",
      "p2 1 Hugh_2951876.mp3.npy\n",
      "p2 1 Hugh_5960178.mp3.npy\n",
      "p2 1 Hugh_7429316.mp3.npy\n",
      "p2 1 Hugh_9675431.mp3.npy\n",
      "p2 1 Hugh_All_I_need_is_some_rest.mp3.npy\n",
      "p2 2 Hugh_Are_you_done_with_the_report.mp3.npy\n",
      "p2 1 Hugh_Can_you_give_me_a_chance.mp3.npy\n",
      "p2 1 Hugh_Even_miracles_take_a_little_time.mp3.npy\n",
      "p2 1 Hugh_I_am_just_about_to_go_to_bed.mp3.npy\n",
      "p2 1 Hugh_I_ate_his_liver_with_some_fava_beans_and_a_nice_Chianti.mp3.npy\n",
      "p2 1 Hugh_I_don’t_think_we_are_in_Kansas_anymore.mp3.npy\n",
      "p2 1 Hugh_I_want_to_access.mp3.npy\n",
      "p2 1 Hugh_That_is_why_I´m_so_tired.mp3.npy\n",
      "p2 1 Hugh_What_do_you_usually_do_in_your_free_time.mp3.npy\n",
      "p2 1 Hugh_What_do_you_want_to_do_today.mp3.npy\n",
      "p2 1 Hugh_Which_one_do_you_want.mp3.npy\n",
      "p2 1 Hugh_Why_are_you_always_putting_me_down.mp3.npy\n",
      "p2 1 Hugh_Would_you_please_be_quiet.mp3.npy\n",
      "p2 1 Hugh_You're_never_wrong_to_do_the_right_things.mp3.npy\n",
      "p2 1 Hugh_education.mp3.npy\n",
      "p2 1 Hugh_explanation.mp3.npy\n",
      "p2 1 Hugh_homogeneous.mp3.npy\n",
      "p2 1 Hugh_innocuous.mp3.npy\n",
      "p2 1 Hugh_meticulous.mp3.npy\n",
      "p2 1 Hugh_piezoelectricity.mp3.npy\n",
      "p2 1 Hugh_precarious.mp3.npy\n",
      "p2 1 Hugh_precipitately.mp3.npy\n",
      "p2 1 Hugh_revolution.mp3.npy\n",
      "p2 1 Hugh_substantive.mp3.npy\n",
      "p3 2 James_1528934.mp3.npy\n",
      "p3 2 James_2951876.mp3.npy\n",
      "p3 2 James_5960178.mp3.npy\n",
      "p3 2 James_7429316.mp3.npy\n",
      "p3 2 James_9675431.mp3.npy\n",
      "p3 2 James_All_I_need_is_some_rest.mp3.npy\n",
      "p3 2 James_Are_you_done_with_the_report.mp3.npy\n",
      "p3 2 James_Can_you_give_me_a_chance.mp3.npy\n",
      "p3 2 James_Even_miracles_take_a_little_time.mp3.npy\n",
      "p3 2 James_I_am_just_about_to_go_to_bed.mp3.npy\n",
      "p3 2 James_I_ate_his_liver_with_some_fava_beans_and_a_nice_Chianti.mp3.npy\n",
      "p3 2 James_I_don’t_think_we_are_in_Kansas_anymore.mp3.npy\n",
      "p3 2 James_I_want_to_access.mp3.npy\n",
      "p3 2 James_That_is_why_I´m_so_tired.mp3.npy\n",
      "p3 2 James_What_do_you_usually_do_in_your_free_time.mp3.npy\n",
      "p3 2 James_What_do_you_want_to_do_today.mp3.npy\n",
      "p3 2 James_Which_one_do_you_want.mp3.npy\n",
      "p3 2 James_Why_are_you_always_putting_me_down.mp3.npy\n",
      "p3 2 James_Would_you_please_be_quiet.mp3.npy\n",
      "p3 2 James_You're_never_wrong_to_do_the_right_things.mp3.npy\n",
      "p3 4 James_education.mp3.npy\n",
      "p3 2 James_explanation.mp3.npy\n",
      "p3 2 James_homogeneous.mp3.npy\n",
      "p3 2 James_innocuous.mp3.npy\n",
      "p3 2 James_meticulous.mp3.npy\n",
      "p3 2 James_piezoelectricity.mp3.npy\n",
      "p3 2 James_precarious.mp3.npy\n",
      "p3 2 James_precipitately.mp3.npy\n",
      "p3 2 James_revolution.mp3.npy\n",
      "p3 2 James_substantive.mp3.npy\n",
      "p4 3 Samantha_1528934.mp3.npy\n",
      "p4 3 Samantha_2951876.mp3.npy\n",
      "p4 3 Samantha_5960178.mp3.npy\n",
      "p4 3 Samantha_7429316.mp3.npy\n",
      "p4 3 Samantha_9675431.mp3.npy\n",
      "p4 3 Samantha_All_I_need_is_some_rest.mp3.npy\n",
      "p4 3 Samantha_Are_you_done_with_the_report.mp3.npy\n",
      "p4 3 Samantha_Can_you_give_me_a_chance.mp3.npy\n",
      "p4 3 Samantha_Even_miracles_take_a_little_time.mp3.npy\n",
      "p4 3 Samantha_I_am_just_about_to_go_to_bed.mp3.npy\n",
      "p4 3 Samantha_I_ate_his_liver_with_some_fava_beans_and_a_nice_Chianti.mp3.npy\n",
      "p4 3 Samantha_I_don’t_think_we_are_in_Kansas_anymore.mp3.npy\n",
      "p4 3 Samantha_I_want_to_access.mp3.npy\n",
      "p4 3 Samantha_That_is_why_I´m_so_tired.mp3.npy\n",
      "p4 3 Samantha_What_do_you_usually_do_in_your_free_time.mp3.npy\n",
      "p4 3 Samantha_What_do_you_want_to_do_today.mp3.npy\n",
      "p4 3 Samantha_Which_one_do_you_want.mp3.npy\n",
      "p4 3 Samantha_Why_are_you_always_putting_me_down.mp3.npy\n",
      "p4 3 Samantha_Would_you_please_be_quiet.mp3.npy\n",
      "p4 3 Samantha_You're_never_wrong_to_do_the_right_things.mp3.npy\n",
      "p4 3 Samantha_education.mp3.npy\n",
      "p4 3 Samantha_explanation.mp3.npy\n",
      "p4 3 Samantha_homogeneous.mp3.npy\n",
      "p4 3 Samantha_innocuous.mp3.npy\n",
      "p4 3 Samantha_meticulous.mp3.npy\n",
      "p4 3 Samantha_piezoelectricity.mp3.npy\n",
      "p4 3 Samantha_precarious.mp3.npy\n",
      "p4 3 Samantha_precipitately.mp3.npy\n",
      "p4 3 Samantha_revolution.mp3.npy\n",
      "p4 3 Samantha_substantive.mp3.npy\n",
      "p5 4 Tom_1528934.mp3.npy\n",
      "p5 4 Tom_2951876.mp3.npy\n",
      "p5 4 Tom_5960178.mp3.npy\n",
      "p5 4 Tom_7429316.mp3.npy\n",
      "p5 4 Tom_9675431.mp3.npy\n",
      "p5 4 Tom_All_I_need_is_some_rest.mp3.npy\n",
      "p5 4 Tom_Are_you_done_with_the_report.mp3.npy\n",
      "p5 4 Tom_Can_you_give_me_a_chance.mp3.npy\n",
      "p5 4 Tom_Even_miracles_take_a_little_time.mp3.npy\n",
      "p5 4 Tom_I_am_just_about_to_go_to_bed.mp3.npy\n",
      "p5 4 Tom_I_ate_his_liver_with_some_fava_beans_and_a_nice_Chianti.mp3.npy\n",
      "p5 4 Tom_I_don’t_think_we_are_in_Kansas_anymore.mp3.npy\n",
      "p5 4 Tom_I_want_to_access.mp3.npy\n",
      "p5 4 Tom_That_is_why_I´m_so_tired.mp3.npy\n",
      "p5 2 Tom_What_do_you_usually_do_in_your_free_time.mp3.npy\n",
      "p5 4 Tom_What_do_you_want_to_do_today.mp3.npy\n",
      "p5 2 Tom_Which_one_do_you_want.mp3.npy\n",
      "p5 4 Tom_Why_are_you_always_putting_me_down.mp3.npy\n",
      "p5 4 Tom_Would_you_please_be_quiet.mp3.npy\n",
      "p5 4 Tom_You're_never_wrong_to_do_the_right_things.mp3.npy\n",
      "p5 4 Tom_education.mp3.npy\n",
      "p5 4 Tom_explanation.mp3.npy\n",
      "p5 4 Tom_homogeneous.mp3.npy\n",
      "p5 4 Tom_innocuous.mp3.npy\n",
      "p5 4 Tom_meticulous.mp3.npy\n",
      "p5 4 Tom_piezoelectricity.mp3.npy\n",
      "p5 4 Tom_precarious.mp3.npy\n",
      "p5 4 Tom_precipitately.mp3.npy\n",
      "p5 4 Tom_revolution.mp3.npy\n",
      "p5 4 Tom_substantive.mp3.npy\n",
      "146\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "vec_list = []\n",
    "features = defaultdict(list)\n",
    "for person in person_list:\n",
    "    for directory in directory_list:\n",
    "        filelist = os.listdir('{}{}/{}/'.format(data_path, person, directory))\n",
    "        for i in testset[directory]:\n",
    "            signal = np.load('{}{}/{}/{}'.format(data_path, person, directory, filelist[i]))\n",
    "            fs = 44100\n",
    "            feat, energy = fbank(signal, samplerate = fs, nfft=calculate_nfft(fs, 0.025))\n",
    "            ffeat = preprocess(energy, feat)\n",
    "            a = [pow(e, np.sum(gmm.score(ffeat)) / len(ffeat)) for gmm in person_gmms]\n",
    "            #print([gmm.score_samples(ffeat).shape for gmm in person_gmms])\n",
    "            if int(person[1]) == a.index(max(a)) + 1:\n",
    "                cnt += 1\n",
    "            print(person, a.index(max(a)), filelist[i])\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_nfft(samplerate, winlen):\n",
    "    window_length_samples = winlen * samplerate\n",
    "    nfft = 1\n",
    "    while nfft < window_length_samples:\n",
    "        nfft *= 2\n",
    "    return nfft\n",
    "\n",
    "def preprocess(energy, feat):\n",
    "    bound = 1.5 * sum(energy[:100]) / 100\n",
    "    ret = []\n",
    "    for i in range(len(energy)):\n",
    "        if energy[i] >= bound:\n",
    "            ret.append(np.log(feat[i, :]))\n",
    "    return np.array(ret)\n",
    "\n",
    "def log_text(string):\n",
    "    print(\"> ML: \" + string)\n",
    "    with open(\"log.txt\", \"a\") as f:\n",
    "        f.write(\"> ML: \" + string + \"\\n\")\n",
    "        f.close()\n",
    "    return\n",
    "\n",
    "def load_list(path_and_file):\n",
    "    with open(path_and_file, \"r\") as f:\n",
    "        output_list = eval(f.readline())\n",
    "        f.close()\n",
    "    return output_list\n",
    "\n",
    "def save_list(path_and_file, input_list):\n",
    "    with open(path_and_file, \"w\") as f:\n",
    "        f.write(str(input_list))\n",
    "        f.close()\n",
    "    return\n",
    "person_list = load_list('ML/model/trained_list.txt')\n",
    "def mkdir(path, directory):        \n",
    "    if (not os.path.exists(path + directory)) or (not os.path.isdir(path + directory)):\n",
    "        os.mkdir(path + directory)\n",
    "    return\n",
    "\n",
    "def listdir(path):\n",
    "    file_list = os.listdir(path)\n",
    "    if '.ipynb_checkpoints' in file_list:\n",
    "        file_list.remove('.ipynb_checkpoints')\n",
    "    return file_list\n",
    "with open('ML/model/model', 'rb') as f:\n",
    "    person_gmms = pickle.load(f)\n",
    "    f.close()\n",
    "        \n",
    "predict_list = []\n",
    "elements = []\n",
    "filelist = listdir('ML/test_data/')\n",
    "for file in filelist:\n",
    "    signal = np.load('ML/test_data/{}'.format(file))\n",
    "    fs = 44100\n",
    "    feat, energy = fbank(signal, samplerate = fs, nfft=calculate_nfft(fs, 0.025))\n",
    "    ffeat = preprocess(energy, feat)\n",
    "    if len(ffeat) == 0:\n",
    "        continue\n",
    "    out = [pow(2.71, np.sum(gmm.score(ffeat)) / len(ffeat)) for gmm in person_gmms]\n",
    "    output = out.index(max(out)) + 1\n",
    "    predict_list.append(output)\n",
    "    if not output in elements:\n",
    "        elements.append(output)\n",
    "print('Test result: {}'.format(predict_list))\n",
    "ret = 0\n",
    "for e in elements:\n",
    "    if predict_list.count(e) / len(predict_list) > 0.6:\n",
    "        ret = e\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lll = os.listdir('ML/test_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1 = np.load('ML/test_data/' + lll[0])\n",
    "s2 = np.load('ML/test_data/' + lll[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
